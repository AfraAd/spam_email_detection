<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Afra Azad" />


<title>InboxIntel Visuals</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">InboxIntel</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="eda.html">EDA</a>
</li>
<li>
  <a href="visuals.html">Visuals</a>
</li>
<li>
  <a href="modeling.html">Modeling</a>
</li>
<li>
  <a href="results.html">Results</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/AfraAd/spam_email_detection">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">InboxIntel Visuals</h1>
<h4 class="author">Afra Azad</h4>

</div>


<div id="visuals" class="section level1">
<h1>üìä Visuals</h1>
<p>This section provides interactive visualizations to better understand
word distributions, frequencies, and patterns in spam vs non-spam
emails. There is also summary table examining the differences in
vocabulary for spam and non-spam emails.</p>
<hr />
<div id="figure-1-tf-idf-vs.-word-frequency-scatter-plot"
class="section level2">
<h2>Figure 1: TF-IDF vs.¬†Word Frequency Scatter Plot</h2>
<p>We examine how frequently a word appears in emails and how important
it is using TF-IDF scores.</p>
<pre class="python"><code># 1. Flatten tokens and count frequencies
spam_words = [word for tokens in df[df.label == 1][&#39;body tokens&#39;] for word in tokens]
non_spam_words = [word for tokens in df[df.label == 0][&#39;body tokens&#39;] for word in tokens]

spam_counts = Counter(spam_words)
nonspam_counts = Counter(non_spam_words)

# Top 20 from each
spam_df = pd.DataFrame(spam_counts.most_common(50), columns=[&quot;word&quot;, &quot;count&quot;])
nonspam_df = pd.DataFrame(nonspam_counts.most_common(50), columns=[&quot;word&quot;, &quot;count&quot;])
spam_df[&quot;label&quot;] = &quot;Spam&quot;
nonspam_df[&quot;label&quot;] = &quot;Non-Spam&quot;

# Combine frequency data
top_words_df = pd.concat([spam_df, nonspam_df], ignore_index=True)

# 2. Prepare TF-IDF on all docs
df[&quot;joined&quot;] = df[&quot;body tokens&quot;].apply(lambda tokens: &quot; &quot;.join(tokens))
spam_docs = df[df.label == 1][&quot;joined&quot;]
nonspam_docs = df[df.label == 0][&quot;joined&quot;]

# Limit vocabulary to the top 20 words from both categories
top_words = top_words_df[&quot;word&quot;].unique().tolist()
vectorizer = TfidfVectorizer(vocabulary=top_words)

# Compute mean TF-IDF for each class
spam_tfidf = vectorizer.fit_transform(spam_docs)
nonspam_tfidf = vectorizer.fit_transform(nonspam_docs)

# Wrap TF-IDF results into DataFrames
spam_scores = pd.DataFrame({
    &quot;word&quot;: vectorizer.get_feature_names_out(),
    &quot;tfidf&quot;: spam_tfidf.mean(axis=0).A1,
    &quot;label&quot;: &quot;Spam&quot;
})

nonspam_scores = pd.DataFrame({
    &quot;word&quot;: vectorizer.get_feature_names_out(),
    &quot;tfidf&quot;: spam_tfidf.mean(axis=0).A1,
    &quot;label&quot;: &quot;Non-Spam&quot;
})

tfidf_df = pd.concat([spam_scores, nonspam_scores], ignore_index=True)

# 3. Merge TF-IDF back with top_words_df
top_words_df = top_words_df.merge(tfidf_df, on=[&quot;word&quot;, &quot;label&quot;], how=&quot;left&quot;)</code></pre>
<pre class="python"><code>IFrame(src=&quot;iframe_figures/figure_1.html&quot;, width=&quot;100%&quot;, height=620)</code></pre>

        <iframe
            width="100%"
            height="620"
            src="iframe_figures/figure_1.html"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
<p><strong>Figure 1</strong> shows the relationship between word
frequency and TF-IDF score for spam and non-spam emails. There appears
to be a linear relationship between word frequency and TF-IDF. However,
the distribution differs by class:</p>
<ul>
<li>Non-spam word frequency has little to no relationship with TF-IDF
and generally has a lower TF-IDF score.</li>
<li>Spam word frequency show a more strictly linear pattern, suggesting
common terms that are spam are also frequent across spam emails.</li>
</ul>
</div>
<div id="figure-2-top-20-most-frequent-bigrams-by-label"
class="section level2">
<h2>Figure 2: Top 20 Most Frequent Bigrams by Label</h2>
<p>This chart shows the most common word pairs (bigrams) in both spam
and non-spam emails.</p>
<pre class="python"><code># Step 1: Generate bigrams
def generate_bigrams(tokens):
    return list(bigrams(tokens))

spam_bigrams = [bg for tokens in df[df[&#39;label&#39;] == 1][&#39;body tokens&#39;] for bg in generate_bigrams(tokens)]
non_spam_bigrams = [bg for tokens in df[df[&#39;label&#39;] == 0][&#39;body tokens&#39;] for bg in generate_bigrams(tokens)]

spam_bigram_counts = Counter(spam_bigrams)
non_spam_bigram_counts = Counter(non_spam_bigrams)

# Step 2: Combine and get top 20 overall bigrams by total frequency
total_bigram_counts = spam_bigram_counts + non_spam_bigram_counts
top_20_bigrams = [f&quot;{a} {b}&quot; for (a, b), _ in total_bigram_counts.most_common(20)]

# Step 3: Build frequency dataframe for Spam and Non-Spam
def bigram_freq_df(counter, label):
    data = [(f&quot;{a} {b}&quot;, count) for (a, b), count in counter.items() if f&quot;{a} {b}&quot; in top_20_bigrams]
    df = pd.DataFrame(data, columns=[&quot;bigram&quot;, &quot;count&quot;])
    df[&quot;label&quot;] = label
    return df

df_spam = bigram_freq_df(spam_bigram_counts, &quot;Spam&quot;)
df_nonspam = bigram_freq_df(non_spam_bigram_counts, &quot;Non-Spam&quot;)

df_bigrams = pd.concat([df_spam, df_nonspam], ignore_index=True)</code></pre>
<pre class="python"><code>IFrame(src=&quot;iframe_figures/figure_2.html&quot;, width=&quot;100%&quot;, height=620)</code></pre>

        <iframe
            width="100%"
            height="620"
            src="iframe_figures/figure_2.html"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
<p><strong>Figure 2</strong> presents the top 20 most frequent bigrams,
labeled by whether they appear in spam or non-spam emails.</p>
<ul>
<li>The top 8 bigrams are all from non-spam emails, likely due to
repetitive work-related words like ‚Äúsubmission‚Äù and ‚Äúsender‚Äù.</li>
<li>The bottom words are spam bigrams. They are more diverse, likely due
to the varied content and tactics used in phishing or promotional
messages.</li>
</ul>
</div>
<div id="figure-3-word-frequency-per-source" class="section level2">
<h2>Figure 3: Word Frequency Per Source</h2>
<p>This chart displays the top 10 most frequent email body tokens for
each dataset, broken down by source and labeled as spam or non-spam.</p>
<pre class="python"><code>df_exploded = df.explode(&quot;body tokens&quot;).dropna(subset=[&quot;body tokens&quot;])
df_exploded[&quot;label&quot;] = df_exploded[&quot;label&quot;].map({0: &quot;Non-Spam&quot;, 1: &quot;Spam&quot;})

word_counts = (
    df_exploded
    .groupby([&quot;source&quot;, &quot;label&quot;, &quot;body tokens&quot;])
    .size()
    .reset_index(name=&quot;count&quot;)
)

# Step 1: Get total counts per token per source (ignoring label)
top10_tokens_per_source = (
    df_exploded
    .groupby([&quot;source&quot;, &quot;body tokens&quot;])
    .size()
    .reset_index(name=&quot;total_count&quot;)
    .sort_values([&quot;source&quot;, &quot;total_count&quot;], ascending=[True, False])
    .groupby(&quot;source&quot;)
    .head(10)
)

# Step 2: Merge with original label-level counts to get spam vs non-spam for each top token
top_words_labeled = (
    word_counts
    .merge(top10_tokens_per_source, on=[&quot;source&quot;, &quot;body tokens&quot;])
)</code></pre>
<pre class="python"><code>IFrame(src=&quot;iframe_figures/figure_3.html&quot;, width=&quot;100%&quot;, height=620)</code></pre>

        <iframe
            width="100%"
            height="620"
            src="iframe_figures/figure_3.html"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
<p><strong>Figure 3</strong> displays the ten most common words in email
bodies for each dataset source, with bars coloured by whether the emails
were spam.</p>
<ul>
<li>The most common words from the CEAS_08 dataset tend to be from
non-spam emails, and words from Nazario and Naigrian_Fraud are all from
spam emails. Conversely, the top words from SpamAssasin are evenly split
between spam and non-spam.</li>
<li>Though CEAS_08 is the only dataset with predominantly spam email,
its top token, has the largest frequency of over 20k. This makes sense
as the top words in the dataset are also the top overall words in our
combined dataset. This could indicate the information from CEAS_08 could
dominate our analysis.</li>
</ul>
<p>Further analysis of these data sources and their impact on our
results is provided in the final report.</p>
</div>
<div id="figure-4-distrubution-of-emails-by-hours-sent"
class="section level2">
<h2>Figure 4: Distrubution of Emails by Hours Sent</h2>
<p>This histogram compares the distribution of spam and non-spam emails
by hour of the day, highlighting differences in their sending
patterns.</p>
<pre class="python"><code>IFrame(src=&quot;iframe_figures/figure_4.html&quot;, width=&quot;100%&quot;, height=620)</code></pre>

        <iframe
            width="100%"
            height="620"
            src="iframe_figures/figure_4.html"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
<p><strong>Figure 4:</strong> displays the distribution of hour of day
email is sent for spam and non-spam email.</p>
<ul>
<li>It appears spam emails tend to be sent during the day; whereas,
non-spam emails are consistently sent throughout the day and night,
especially at 8 am. This makes sense as many work emails are scheduled
to be sent at the beginning of the work day at 8.</li>
<li>Hour sent can be a useful variable for our modelling.</li>
</ul>
</div>
<div id="table-1-summary-statisacs-of-difference-in-vocabulary"
class="section level2">
<h2>Table 1: Summary Statisacs of Difference in Vocabulary</h2>
<p>The following table summarizes the differences in lexical diversity
between spam and non-spam emails. Lexical diversity measures the
percentage of unique words within each group.</p>
<pre class="python"><code># Create a dictionary with the summary statistics
summary_data = {
    &quot;Metric&quot;: [
        &quot;Unique Words&quot;,
        &quot;Total Words&quot;,
        &quot;Average Words per Email&quot;,
        &quot;Lexical Diversity&quot;
    ],
    &quot;Spam Emails&quot;: [
        len(set(spam_words)),
        len(spam_words),
        df[df.label == 1][&#39;body tokens&#39;].apply(len).mean(),
        len(set(spam_words)) / len(spam_words)
    ],
    &quot;Non-Spam Emails&quot;: [
        len(set(non_spam_words)),
        len(non_spam_words),
        df[df.label == 0][&#39;body tokens&#39;].apply(len).mean(),
        len(set(non_spam_words)) / len(non_spam_words)
    ]
}

# Convert to a pandas DataFrame
summary_df = pd.DataFrame(summary_data)

# Format numbers for readability
summary_df[&quot;Spam Emails&quot;] = summary_df[&quot;Spam Emails&quot;].apply(lambda x: f&quot;{x:.4f}&quot;)
summary_df[&quot;Non-Spam Emails&quot;] = summary_df[&quot;Non-Spam Emails&quot;].apply(lambda x: f&quot;{x:.4f}&quot;)</code></pre>
<pre class="python"><code>print(tabulate(summary_df, headers=&#39;keys&#39;, tablefmt=&#39;pretty&#39;, showindex=False))</code></pre>
<pre><code>## +-------------------------+--------------+-----------------+
## |         Metric          | Spam Emails  | Non-Spam Emails |
## +-------------------------+--------------+-----------------+
## |      Unique Words       | 150547.0000  |   131351.0000   |
## |       Total Words       | 2054541.0000 |  3646719.0000   |
## | Average Words per Email |   75.9198    |    177.7240     |
## |    Lexical Diversity    |    0.0733    |     0.0360      |
## +-------------------------+--------------+-----------------+</code></pre>
<p>Spam emails tend to contain fewer words but have more unique words
and a larger lexicon. This suggests that spam emails may use uncommon
words in non-spam emails, which will be useful knowledge for our
modeling.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
